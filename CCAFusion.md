Title: CCAFusion: Cross-Modal Coordinate Attention  Network for Infrared and Visible Image Fusion

labels: #imagefusion 

# Brief

该论文设计了跨模态图像融合策略：特征感知融合模块+特征增强融合模块，开发了新的多约束损失函数，应用了多尺度跳跃链接网络，引入了坐标注意力机制。

**数据类型**: RGB-灰度 & RGB-IR

# Translation

## Abstract

红外和可见光图像融合旨在生成具有全面信息的图像。它可以保持丰富的纹理特性和热信息。然而，对于现有的图像融合方法，融合图像要么牺牲了热目标的显著性和纹理的丰富性，要么引入了伪影等无用信息的干扰。

为了缓解这些问题，该文提出了一种有效的红外可见光图像融合跨模态坐标注意力网络CCAFusion。为了充分融合互补特征，设计了基于坐标注意力的跨模态图像融合策略，该策略由 **特征感知融合模块** 和 **特征增强融合模块组成**。此外，采用基于 **多尺度跳跃连接的网络** 在红外图像和可见光图像中获得多尺度特征，在融合过程中可以充分利用多级信息。为了减少融合图像与输入图像之间的差异，该文开发了包括 **基数损失** 和 **辅助损失** 的多重约束损失函数，以调整融合图像中的灰度分布，保证结构和强度的和谐共存，从而防止伪影等无用信息的污染。

在广泛使用的数据集上进行的广泛实验表明，我们的 CCAFusion 在定性评估和定量测量方面都取得了优于最先进的图像融合方法的性能。此外，在显著目标检测中的应用揭示了我们的 CCAFusion 在高级视觉任务中的潜力，可以有效地提高检测性能。

# Notes

不使用通道注意力（如SE模块），而是采用了坐标（像素角度）的注意力机制，可以同时学到通道、位置和长程依赖

### 长程依赖

距离较远的局部关系

eg. "The cat, which chased the dog that ran across the field and jumped over the fence, was black." 句子开头的 "cat" 和结尾的 "was" 之间有直接的主谓一致关系。

eg. 在图像中： 想象一张全身人像照片。人的眼睛（在图像上方）和他的鞋子（在图像下方）在空间上相距很远。

SE模块简单粗暴的在S阶段直接将每一个通道的特征图压缩成了一个点（使用全局平均池化），从根本上失去了学习到位置信息的机会。

而坐标注意力，则分别在x轴y轴两个方向做单列单行的池化，保留了特征x，y坐标的信息，从而能够学习到位置与方向信息，从而学习到了长程依赖关系。